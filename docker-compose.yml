version: '3.8'

services:
  vla-gr:
    build:
      context: .
      dockerfile: Dockerfile
      target: app
    image: vla-gr:latest
    container_name: vla-gr-app
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONUNBUFFERED=1
    volumes:
      - ./checkpoints:/app/checkpoints
      - ./logs:/app/logs
      - ./data:/app/data
      - ./outputs:/app/outputs
    ports:
      - "8000:8000"  # API server
      - "6006:6006"  # TensorBoard
    shm_size: '8gb'
    stdin_open: true
    tty: true

  vla-gr-dev:
    build:
      context: .
      dockerfile: Dockerfile
      target: dev
    image: vla-gr:dev
    container_name: vla-gr-dev
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONUNBUFFERED=1
    volumes:
      - .:/app
      - ./checkpoints:/app/checkpoints
      - ./logs:/app/logs
      - ./data:/app/data
      - ./outputs:/app/outputs
    ports:
      - "8000:8000"
      - "6006:6006"
      - "8888:8888"  # Jupyter
    shm_size: '8gb'
    stdin_open: true
    tty: true
    command: /bin/bash

  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: vla-gr-tensorboard
    volumes:
      - ./logs:/logs
    ports:
      - "6007:6006"
    command: tensorboard --logdir=/logs --host=0.0.0.0
