# VLA-GR Training Configuration for Server (Multi-GPU: 4x A100/H100 80GB)
# High-performance configuration for maximal performance
# Expected training time: ~12-24 hours for SOTA convergence

defaults:
  - _self_
  - model: vla_gr_enhanced
  - training: server
  - environment: habitat
  - hardware: server

project:
  name: "VLA-GR-Enhanced-Server"
  version: "2.0.0"
  description: "Enhanced VLA-GR with full SOTA modules for server training"
  seed: 42
  debug: false
  log_level: "INFO"
  experiment_name: "server_sota_full"

model:
  # Vision Encoder (Full capacity)
  vision:
    backbone: "dinov2_vitl14"  # Largest DINOv2 variant
    input_size: [336, 336]  # Higher resolution
    depth_channels: 1
    use_depth: true
    pretrained: true
    freeze_backbone: false  # Fine-tune entire backbone

  # Language Encoder (Powerful)
  language:
    model: "microsoft/phi-2"  # Could use larger like Phi-3
    max_tokens: 512  # Increased context
    embed_dim: 768
    vocab_size: 50304
    use_cache: true
    gradient_checkpointing: false  # Disabled for speed

  # VLA Transformer (Full capacity)
  vla:
    hidden_dim: 1024  # Increased from 768
    num_layers: 16  # Increased from 12
    num_heads: 16
    mlp_ratio: 4.0
    dropout: 0.1
    action_dim: 7
    use_flash_attention: true  # Enable for speed

  # Enhanced: Diffusion Policy Module (Full)
  diffusion_policy:
    enabled: true
    action_dim: 7
    hidden_dim: 512  # Full capacity
    context_dim: 1024
    num_layers: 8  # Increased
    num_heads: 16
    num_diffusion_steps: 100  # Full diffusion steps
    prediction_type: "v_prediction"
    max_action_horizon: 32  # Long horizon planning
    num_inference_steps: 20  # More steps for quality
    dropout: 0.05

  # Enhanced: Dual-System Architecture (Full)
  dual_system:
    enabled: true
    visual_dim: 1024
    vlm_dim: 1024
    proprio_dim: 7
    action_dim: 7
    s1_hidden_dim: 512  # Large S1
    s2_hidden_dim: 1024  # Large S2
    s1_layers: 4
    s2_reasoning_steps: 4  # More reasoning
    max_subgoals: 8  # More subgoals
    planning_frequency_hz: 5.0  # Higher planning frequency
    control_frequency_hz: 50.0  # Full 50Hz control
    confidence_threshold: 0.6

  # Enhanced: Trajectory Attention (Full)
  trajectory_attention:
    enabled: true
    hidden_dim: 512
    num_layers: 6  # More layers
    num_heads: 16
    num_action_queries: 32  # More queries
    mlp_ratio: 4.0
    dropout: 0.05
    use_rope: true
    max_trajectory_len: 200

  # Enhanced: PEFT (Optional - can disable for full fine-tuning)
  peft:
    method: "oft"  # OFT recommended for better performance
    enabled: false  # Disable for full fine-tuning on server
    lora_rank: 16  # Higher rank if enabled
    lora_alpha: 32
    lora_dropout: 0.05
    oft_rank: 8
    target_modules: ["q_proj", "v_proj", "k_proj", "out_proj"]

  # GR Field Parameters (Full resolution)
  gr_field:
    grid_size: [128, 128, 64]  # High resolution
    field_dim: 10
    c: 1.0
    G: 1.0
    lambda_curvature: 0.1
    max_mass: 10.0
    use_sparse_computation: false  # Full computation
    use_mixed_precision_field: true  # Speed optimization

  # Affordance Quantification (Enhanced)
  affordance:
    num_classes: 80
    sigma_min: 0.1
    sigma_max: 2.0
    confidence_threshold: 0.25  # Lower for more detections
    use_bayesian_update: true
    bayesian_prior_strength: 1.0
    multi_scale: true  # Multi-scale affordance

  # Path Optimization (Full)
  path:
    horizon: 100  # Long horizon
    dt: 0.05  # Finer time steps
    max_velocity: 2.5
    max_acceleration: 6.0
    collision_radius: 0.25
    geodesic_samples: 200  # More samples
    optimization_steps: 50  # More optimization
    use_learned_cost: true  # Learn cost function

  # Occlusion Handling (Enhanced)
  occlusion:
    completion_model: "unet"
    unet_channels: [64, 128, 256, 512]  # Larger UNet
    mask_ratio_train: 0.3  # More aggressive augmentation
    mask_ratio_test: 0.2
    completion_threshold: 0.4
    uncertainty_aware: true
    multi_scale_completion: true

training:
  # Optimization
  optimizer: "adamw"
  learning_rate: 1e-4  # Higher LR for faster convergence
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1e-8
  scheduler: "cosine"
  warmup_steps: 2000
  max_steps: 200000  # Longer training
  gradient_clip: 1.0

  # Batch Sizes (Large for multi-GPU)
  batch_size: 16  # Per GPU
  eval_batch_size: 32
  gradient_accumulation: 2  # Effective batch: 16*4*2=128

  # Data Loading (Optimized)
  num_workers: 16  # More workers
  pin_memory: true
  prefetch_factor: 4  # Aggressive prefetching
  persistent_workers: true

  # Losses (Comprehensive weighting)
  losses:
    action: 1.0
    field: 0.5
    affordance: 0.4
    depth: 0.3
    entropy: 0.01
    diffusion: 0.8  # Higher weight for diffusion
    dual_system_s1: 0.4  # S1 fast policy loss
    dual_system_s2: 0.3  # S2 planning loss
    trajectory: 0.6  # Trajectory prediction
    consistency: 0.2  # Cross-module consistency
    curriculum: 0.1  # Curriculum learning bonus

  # Advanced Augmentation
  augment:
    random_crop: true
    crop_scale: [0.8, 1.0]
    color_jitter: true
    brightness: 0.2
    contrast: 0.2
    saturation: 0.1
    hue: 0.05
    gaussian_noise: 0.02
    depth_noise: 0.03
    random_occlusion: true
    occlusion_prob: 0.3
    mixup: true  # Mixup augmentation
    mixup_alpha: 0.4

  # Checkpointing
  save_every: 2000
  eval_every: 1000
  checkpoint_dir: "checkpoints/server/"
  keep_last_n_checkpoints: 10
  keep_best_n_checkpoints: 5
  resume: null
  save_optimizer_state: true

  # Mixed Precision (BF16 for A100/H100)
  mixed_precision: true
  fp16: false
  bf16: true  # Better for A100/H100
  fp16_opt_level: "O2"
  tf32: true  # Enable TF32

  # Memory Optimization (Minimal on server)
  memory:
    gradient_checkpointing: false  # Disabled for speed
    empty_cache_every: 500  # Less frequent
    max_memory_gb: 75  # Per GPU
    use_cpu_offload: false
    activation_checkpointing: false

  # Curriculum Learning
  curriculum:
    enabled: true
    start_difficulty: 0.3
    end_difficulty: 1.0
    difficulty_schedule: "linear"
    difficulty_steps: 100000

  # EMA (Exponential Moving Average)
  ema:
    enabled: true
    decay: 0.9999
    update_every: 10

environment:
  # Habitat Configuration (Full dataset)
  habitat:
    scene_dataset: "hm3d"  # Full HM3D dataset
    split: "train"
    max_episode_steps: 1000  # Long episodes
    success_distance: 0.15  # Stricter success
    num_scenes: -1  # All scenes
    scene_shuffle: true

  # Sensors (High resolution)
  sensors:
    rgb:
      width: 960  # High resolution
      height: 720
      fov: 79
      hfov: 90
    depth:
      width: 960
      height: 720
      min_depth: 0.0
      max_depth: 10.0
      noise_model: "redwood"
    semantic:
      width: 960
      height: 720
    # Additional sensors
    gps:
      enabled: true
    compass:
      enabled: true

  # Task (Comprehensive)
  task:
    type: "objectnav"
    goals: ["chair", "couch", "bed", "toilet", "tv_monitor",
            "plant", "refrigerator", "table", "picture", "counter"]
    reward_success: 10.0
    reward_collision: -0.2
    reward_forward: 0.02
    slack_reward: -0.001
    reward_shaping: true  # Additional reward shaping
    sparse_reward: false

  # Multi-task learning
  multi_task:
    enabled: true
    tasks: ["objectnav", "pointnav", "imagenav"]
    task_sampling: "uniform"

evaluation:
  # Metrics (Comprehensive)
  metrics:
    - "success_rate"
    - "spl"
    - "soft_spl"
    - "collision_rate"
    - "distance_to_goal"
    - "trajectory_length"
    - "trajectory_efficiency"
    - "field_accuracy"
    - "affordance_precision"
    - "affordance_recall"
    - "diffusion_mse"
    - "diffusion_fid"  # Frechet Inception Distance
    - "planning_frequency"
    - "s1_action_diversity"
    - "s2_plan_coherence"
    - "inference_latency_ms"
    - "throughput_fps"

  # Evaluation Settings
  num_episodes: 5000  # Comprehensive evaluation
  visualize: true
  save_trajectories: true
  save_videos: true
  video_fps: 30
  save_attention_maps: true
  save_field_visualizations: true

  # Benchmark suites
  benchmarks:
    - "objectnav_hm3d_val"
    - "objectnav_mp3d_val"
    - "objectnav_gibson_val"

deployment:
  # Model Export
  export:
    onnx: true
    tensorrt: true  # TensorRT for inference
    tensorrt_precision: "fp16"
    quantize: true
    quantization_method: "dynamic"  # Dynamic INT8
    optimize_for_mobile: false
    optimize_for_edge: false

  # Serving (Production-ready)
  server:
    host: "0.0.0.0"
    port: 8080
    workers: 8  # Multiple workers
    max_batch_size: 32
    timeout: 60
    use_triton: true  # NVIDIA Triton Inference Server
    enable_metrics: true

  # Robot Interface
  robot:
    type: "ros2"
    control_frequency: 50
    safety_checks: true
    emergency_stop: true
    collision_avoidance: true
    dynamic_obstacle_avoidance: true

hardware:
  # GPU Settings (Multi-GPU)
  device: "cuda"
  num_gpus: 4  # 4x A100/H100
  gpu_ids: [0, 1, 2, 3]
  allow_tf32: true

  # Distributed Training (DDP)
  distributed:
    enabled: true
    backend: "nccl"
    world_size: 4
    init_method: "env://"
    find_unused_parameters: false
    gradient_as_bucket_view: true
    static_graph: true  # Optimization

  # Memory Management
  memory:
    gradient_checkpointing: false
    empty_cache_every: 500
    max_memory_gb: 75
    reserved_memory_gb: 5

  # Performance Optimizations
  optimizations:
    channels_last: true  # Memory format optimization
    cudnn_benchmark: true
    cudnn_deterministic: false
    compile_model: true  # torch.compile for PyTorch 2.0+
    compile_mode: "reduce-overhead"

logging:
  # Weights & Biases
  wandb:
    enabled: true
    project: "vla-gr-server"
    entity: null
    tags: ["vla", "gr", "navigation", "server", "sota", "multi-gpu"]
    notes: "Server training with all SOTA enhancements"
    log_frequency: 100
    log_model: "checkpoint"  # Log model checkpoints

  # Tensorboard
  tensorboard:
    enabled: true
    log_dir: "logs/server/"
    log_frequency: 50

  # Console
  console:
    enabled: true
    format: "[%(asctime)s] [GPU%(gpu)s] %(levelname)s - %(message)s"
    log_every: 100

  # File
  file:
    enabled: true
    path: "logs/server/vla_gr.log"
    max_size_mb: 500
    backup_count: 10

  # Profiling
  profiling:
    enabled: true
    profile_memory: true
    profile_cpu: true
    profile_cuda: true
    wait: 5
    warmup: 5
    active: 10
    repeat: 2

# Performance Targets for Server (4x A100 80GB)
# Expected metrics after 200k steps (~20h training):
# - Success Rate: 85-90% (SOTA target, +7-13% vs baseline 77.4%)
# - SPL: >0.75
# - Collision Rate: <12% (vs 16.5% baseline)
# - Inference Latency: <15ms (50Hz capable)
# - Training Speed: ~20-30 steps/sec (with 4 GPUs)
# - Peak VRAM per GPU: ~65-70GB
# - Total Training Time: 18-24 hours
# - FLOPs: ~500 GFLOPs per forward pass
#
# Key SOTA Improvements:
# 1. Diffusion Policy: +3-5% success rate, more stable actions
# 2. Dual-System: +2-4% success rate, better long-horizon planning
# 3. Trajectory Attention: +2-3% success rate, smoother trajectories
# 4. Higher resolution inputs: +1-2% success rate
# 5. Advanced augmentation: +1-2% robustness
# Total expected improvement: +9-16% over baseline â†’ 86-93% success rate

# Hydra Configuration
hydra:
  run:
    dir: outputs/server/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/server/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    config:
      override_dirname:
        kv_sep: "="
        item_sep: ","
