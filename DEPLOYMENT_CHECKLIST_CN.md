# VLA-GR Habitat 0.3.3 è¯¦ç»†éƒ¨ç½² Checklist å’Œæ•™ç¨‹

> **ç‰ˆæœ¬**: 1.0.0
> **é€‚ç”¨ç¯å¢ƒ**: Linux (Ubuntu 20.04/22.04), CUDA 11.8+
> **æœ€åæ›´æ–°**: 2025-11-09

---

## ğŸ“‹ éƒ¨ç½² Checklist

### é˜¶æ®µä¸€ï¼šç¯å¢ƒå‡†å¤‡ âœ…

- [ ] **1.1** æ£€æŸ¥ç³»ç»Ÿè¦æ±‚ï¼ˆGPUã€å†…å­˜ã€å­˜å‚¨ï¼‰
- [ ] **1.2** å®‰è£… CUDA 11.8+ å’Œ cuDNN
- [ ] **1.3** å®‰è£… Python 3.9-3.11
- [ ] **1.4** åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
- [ ] **1.5** é…ç½®ç¯å¢ƒå˜é‡

### é˜¶æ®µäºŒï¼šåŸºç¡€ä¾èµ–å®‰è£… âœ…

- [ ] **2.1** å®‰è£… PyTorch 2.0+ï¼ˆCUDAç‰ˆæœ¬ï¼‰
- [ ] **2.2** å®‰è£… Habitat-Sim 0.3.3
- [ ] **2.3** å®‰è£… Habitat-Lab 0.3.3
- [ ] **2.4** éªŒè¯ Habitat å®‰è£…
- [ ] **2.5** å®‰è£…é¡¹ç›®ä¾èµ–ï¼ˆrequirements.txtï¼‰

### é˜¶æ®µä¸‰ï¼šæ•°æ®é›†ä¸‹è½½å’Œé…ç½® âœ…

- [ ] **3.1** åˆ›å»ºæ•°æ®ç›®å½•ç»“æ„
- [ ] **3.2** ä¸‹è½½ Habitat æµ‹è¯•åœºæ™¯ï¼ˆReplicaï¼‰
- [ ] **3.3** ä¸‹è½½ HM3D æ•°æ®é›†ï¼ˆå¯é€‰ï¼Œè®­ç»ƒç”¨ï¼‰
- [ ] **3.4** ä¸‹è½½ ObjectNav ä»»åŠ¡æ•°æ®
- [ ] **3.5** é…ç½®æ•°æ®é›†è·¯å¾„
- [ ] **3.6** éªŒè¯æ•°æ®é›†å®Œæ•´æ€§

### é˜¶æ®µå››ï¼šHugging Face æ¨¡å‹éƒ¨ç½² âœ…

- [ ] **4.1** é…ç½® Hugging Face è®¿é—®ï¼ˆtokenï¼‰
- [ ] **4.2** ä¸‹è½½ Microsoft Phi-2 æ¨¡å‹
- [ ] **4.3** ä¸‹è½½ CLIP æ¨¡å‹
- [ ] **4.4** ä¸‹è½½ BERT æ¨¡å‹ï¼ˆåå¤‡ï¼‰
- [ ] **4.5** é…ç½®æ¨¡å‹ç¼“å­˜è·¯å¾„
- [ ] **4.6** éªŒè¯æ¨¡å‹åŠ è½½

### é˜¶æ®µäº”ï¼šé¡¹ç›®å®‰è£…å’Œé…ç½® âœ…

- [ ] **5.1** å…‹éš†é¡¹ç›®ä»£ç 
- [ ] **5.2** å®‰è£…é¡¹ç›®ï¼ˆeditable modeï¼‰
- [ ] **5.3** é…ç½® config.yaml
- [ ] **5.4** è®¾ç½® Weights & Biasesï¼ˆå¯é€‰ï¼‰
- [ ] **5.5** åˆ›å»ºè¾“å‡ºç›®å½•

### é˜¶æ®µå…­ï¼šéªŒè¯å’Œæµ‹è¯• âœ…

- [ ] **6.1** è¿è¡Œå¯¼å…¥æµ‹è¯•
- [ ] **6.2** è¿è¡Œ Habitat ç¯å¢ƒæµ‹è¯•
- [ ] **6.3** è¿è¡Œæ¨¡å‹åŠ è½½æµ‹è¯•
- [ ] **6.4** è¿è¡Œç®€å•æ¨ç†æµ‹è¯•
- [ ] **6.5** æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨

### é˜¶æ®µä¸ƒï¼šè®­ç»ƒå’Œè¯„ä¼° âœ…

- [ ] **7.1** å‡†å¤‡è®­ç»ƒé…ç½®
- [ ] **7.2** è¿è¡Œå°è§„æ¨¡è®­ç»ƒæµ‹è¯•
- [ ] **7.3** å¯åŠ¨å®Œæ•´è®­ç»ƒ
- [ ] **7.4** ç›‘æ§è®­ç»ƒè¿›åº¦
- [ ] **7.5** è¿è¡Œè¯„ä¼°

---

## ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®ï¼ˆæµ‹è¯•/å¼€å‘ï¼‰

```yaml
ç¡¬ä»¶è¦æ±‚:
  GPU: NVIDIA RTX 3060 (12GB) æˆ–æ›´é«˜
  CPU: 8æ ¸å¿ƒä»¥ä¸Š
  å†…å­˜: 32GB RAM
  å­˜å‚¨: 100GB å¯ç”¨ç©ºé—´ï¼ˆåŸºç¡€ç¯å¢ƒ + Replicaåœºæ™¯ï¼‰

è½¯ä»¶è¦æ±‚:
  æ“ä½œç³»ç»Ÿ: Ubuntu 20.04/22.04 LTS
  CUDA: 11.8 æˆ– 12.1
  cuDNN: 8.x
  Python: 3.9, 3.10, æˆ– 3.11
  GCC: 7.x æˆ–æ›´é«˜ï¼ˆç¼–è¯‘Habitat-Siméœ€è¦ï¼‰
```

### æ¨èé…ç½®ï¼ˆè®­ç»ƒï¼‰

```yaml
RTX 4060 é…ç½®ï¼ˆ8GBæ˜¾å­˜ï¼‰:
  GPU: NVIDIA RTX 4060
  å†…å­˜: 32GB RAM
  å­˜å‚¨: 500GB SSDï¼ˆåŒ…å«éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼‰
  é¢„æœŸè®­ç»ƒæ—¶é—´: 48-72å°æ—¶
  é¢„æœŸæˆåŠŸç‡: ~80%

æœåŠ¡å™¨é…ç½®ï¼ˆç”Ÿäº§çº§ï¼‰:
  GPU: 4x NVIDIA A100 (80GB) æˆ– H100
  å†…å­˜: 256GB+ RAM
  å­˜å‚¨: 4TB NVMe SSDï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰
  é¢„æœŸè®­ç»ƒæ—¶é—´: 18-24å°æ—¶
  é¢„æœŸæˆåŠŸç‡: 85-90%
```

---

## ğŸ“¦ é˜¶æ®µä¸€ï¼šç¯å¢ƒå‡†å¤‡

### 1.1 æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯

```bash
# æ£€æŸ¥æ“ä½œç³»ç»Ÿ
cat /etc/os-release

# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥å¯ç”¨å­˜å‚¨
df -h

# æ£€æŸ¥å†…å­˜
free -h
```

### 1.2 å®‰è£… CUDA å’Œ cuDNN

å¦‚æœè¿˜æ²¡æœ‰å®‰è£… CUDAï¼š

```bash
# Ubuntu 22.04 å®‰è£… CUDA 12.1ï¼ˆæ¨èï¼‰
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-1

# æˆ–è€…å®‰è£… CUDA 11.8ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰
sudo apt-get -y install cuda-toolkit-11-8

# å®‰è£… cuDNN
# ä» NVIDIA å®˜ç½‘ä¸‹è½½å¯¹åº”ç‰ˆæœ¬ï¼šhttps://developer.nvidia.com/cudnn
# ç„¶åå®‰è£…ï¼š
sudo dpkg -i libcudnn8_*.deb
sudo dpkg -i libcudnn8-dev_*.deb
```

### 1.3 å®‰è£… Python 3.9-3.11

```bash
# Ubuntu 22.04 è‡ªå¸¦ Python 3.10
python3 --version

# å¦‚æœéœ€è¦å®‰è£…å…¶ä»–ç‰ˆæœ¬ï¼š
sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install python3.10 python3.10-dev python3.10-venv

# å®‰è£… pip
sudo apt install python3-pip
```

### 1.4 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p ~/vla-gr-workspace
cd ~/vla-gr-workspace

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv vla-gr-env

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source vla-gr-env/bin/activate

# å‡çº§ pip
pip install --upgrade pip setuptools wheel
```

### 1.5 é…ç½®ç¯å¢ƒå˜é‡

```bash
# ç¼–è¾‘ ~/.bashrc
nano ~/.bashrc

# æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼ˆæ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬è°ƒæ•´ï¼‰ï¼š
export CUDA_HOME=/usr/local/cuda-12.1
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# Habitat æ•°æ®è·¯å¾„ï¼ˆç¨åä¼šåˆ›å»ºï¼‰
export HABITAT_DATA_DIR=~/vla-gr-workspace/habitat-data
export HABITAT_SCENE_DATASETS_DIR=$HABITAT_DATA_DIR/scene_datasets

# Hugging Face ç¼“å­˜è·¯å¾„
export HF_HOME=~/vla-gr-workspace/huggingface-cache
export TRANSFORMERS_CACHE=$HF_HOME/transformers

# åº”ç”¨æ›´æ”¹
source ~/.bashrc
```

---

## ğŸ”§ é˜¶æ®µäºŒï¼šåŸºç¡€ä¾èµ–å®‰è£…

### 2.1 å®‰è£… PyTorch 2.0+

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/vla-gr-workspace/vla-gr-env/bin/activate

# å®‰è£… PyTorch 2.1.0 with CUDA 12.1ï¼ˆæ¨èï¼‰
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121

# æˆ–è€…ä½¿ç”¨ CUDA 11.8
# pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# éªŒè¯å®‰è£…
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'CUDA Version: {torch.version.cuda}')"
```

**é¢„æœŸè¾“å‡º**:
```
PyTorch: 2.1.0+cu121
CUDA Available: True
CUDA Version: 12.1
```

### 2.2 å®‰è£… Habitat-Sim 0.3.3

è¿™æ˜¯æœ€å…³é”®çš„ä¸€æ­¥ï¼Habitat-Sim éœ€è¦ä»æºç ç¼–è¯‘ã€‚

#### å®‰è£…ä¾èµ–

```bash
# å®‰è£…ç¼–è¯‘å·¥å…·
sudo apt-get update
sudo apt-get install -y \
    build-essential \
    cmake \
    git \
    libegl1-mesa-dev \
    libgl1-mesa-dev \
    libgles2-mesa-dev \
    libosmesa6-dev \
    wget \
    unzip \
    libjpeg-dev \
    libpng-dev \
    ninja-build
```

#### ä»æºç å®‰è£… Habitat-Sim

```bash
# åˆ›å»ºæ„å»ºç›®å½•
mkdir -p ~/vla-gr-workspace/habitat-build
cd ~/vla-gr-workspace/habitat-build

# å…‹éš† Habitat-Sim ä»“åº“ï¼ˆä½¿ç”¨ 0.3.3 åˆ†æ”¯ï¼‰
git clone --branch v0.3.3 https://github.com/facebookresearch/habitat-sim.git
cd habitat-sim

# å®‰è£… Python ä¾èµ–
pip install -r requirements.txt

# æ„å»ºå’Œå®‰è£…ï¼ˆè¿™ä¸€æ­¥ä¼šèŠ±è´¹ 15-30 åˆ†é’Ÿï¼‰
# ä½¿ç”¨ --headless æ¨¡å¼ï¼ˆæœåŠ¡å™¨ç¯å¢ƒï¼‰
python setup.py install --headless --with-cuda

# æˆ–è€…ä½¿ç”¨ --bulletï¼ˆå¦‚æœéœ€è¦ç‰©ç†å¼•æ“ï¼‰
# python setup.py install --headless --with-cuda --with-bullet
```

**ç¼–è¯‘é€‰é¡¹è¯´æ˜**:
- `--headless`: æ— å¤´æ¨¡å¼ï¼ˆæ— éœ€X11æ˜¾ç¤ºï¼‰
- `--with-cuda`: å¯ç”¨ CUDA åŠ é€Ÿ
- `--with-bullet`: å¯ç”¨ Bullet ç‰©ç†å¼•æ“ï¼ˆå¯é€‰ï¼‰

#### éªŒè¯å®‰è£…

```bash
python -c "import habitat_sim; print(f'Habitat-Sim version: {habitat_sim.__version__}')"
```

**é¢„æœŸè¾“å‡º**: `Habitat-Sim version: 0.3.3`

### 2.3 å®‰è£… Habitat-Lab 0.3.3

```bash
# è¿”å›æ„å»ºç›®å½•
cd ~/vla-gr-workspace/habitat-build

# å…‹éš† Habitat-Lab ä»“åº“
git clone --branch v0.3.3 https://github.com/facebookresearch/habitat-lab.git
cd habitat-lab

# å®‰è£…
pip install -e habitat-lab
pip install -e habitat-baselines
```

### 2.4 éªŒè¯ Habitat å®‰è£…

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_habitat.py`:

```python
import habitat
from habitat.config import read_write
from habitat.config.default import get_agent_config
from habitat_sim import make_sim

print(f"Habitat version: {habitat.__version__}")

# åˆ›å»ºåŸºç¡€é…ç½®
with read_write(habitat.get_config()):
    config = habitat.get_config()
    print("âœ“ Config created successfully")

print("âœ“ Habitat installation verified!")
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_habitat.py
```

### 2.5 å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# è¿”å›åˆ°é¡¹ç›®ç›®å½•ï¼ˆç¨åä¼šå…‹éš†ï¼‰
# è¿™é‡Œå…ˆå®‰è£…æ ¸å¿ƒä¾èµ–

# å®‰è£… Transformers å’Œç›¸å…³åº“
pip install transformers>=4.30.0 tokenizers>=0.13.0 accelerate>=0.20.0

# å®‰è£… 3D å¤„ç†åº“
pip install open3d>=0.17.0 trimesh>=3.21.0

# å®‰è£…ä¼˜åŒ–åº“
pip install cvxpy>=1.3.0 osqp>=0.6.2 sympy>=1.11.0

# å®‰è£…å¯è§†åŒ–åº“
pip install matplotlib>=3.7.0 wandb>=0.15.0 tensorboard>=2.12.0

# å®‰è£…å…¶ä»–ä¾èµ–
pip install \
    numpy>=1.24.0 \
    scipy>=1.10.0 \
    scikit-learn>=1.2.0 \
    pillow>=9.5.0 \
    opencv-python>=4.7.0 \
    pyyaml>=6.0 \
    tqdm>=4.65.0 \
    hydra-core>=1.3.0 \
    omegaconf>=2.3.0

# å®‰è£…éƒ¨ç½²ç›¸å…³
pip install onnx>=1.14.0 onnxruntime-gpu>=1.14.0 fastapi>=0.95.0 uvicorn>=0.21.0

# å®‰è£… PyBulletï¼ˆç‰©ç†æ¨¡æ‹Ÿï¼‰
pip install pybullet>=3.2.5
```

---

## ğŸ“ é˜¶æ®µä¸‰ï¼šæ•°æ®é›†ä¸‹è½½å’Œé…ç½®

### 3.1 åˆ›å»ºæ•°æ®ç›®å½•ç»“æ„

```bash
# åˆ›å»ºä¸»æ•°æ®ç›®å½•
mkdir -p $HABITAT_DATA_DIR
cd $HABITAT_DATA_DIR

# åˆ›å»ºå­ç›®å½•
mkdir -p scene_datasets
mkdir -p datasets/objectnav/hm3d/v1
mkdir -p datasets/pointnav/habitat_test_scenes
mkdir -p objects
mkdir -p episodes

# ç›®å½•ç»“æ„ï¼š
# habitat-data/
# â”œâ”€â”€ scene_datasets/          # 3D åœºæ™¯æ•°æ®
# â”‚   â”œâ”€â”€ hm3d/               # HM3D æ•°æ®é›†
# â”‚   â”œâ”€â”€ mp3d/               # Matterport3D
# â”‚   â””â”€â”€ replica/            # Replicaï¼ˆæµ‹è¯•ç”¨ï¼‰
# â”œâ”€â”€ datasets/               # ä»»åŠ¡æ•°æ®ï¼ˆepisodesï¼‰
# â”‚   â”œâ”€â”€ objectnav/
# â”‚   â””â”€â”€ pointnav/
# â””â”€â”€ objects/                # å¯¹è±¡æ¨¡å‹
```

### 3.2 ä¸‹è½½ Habitat æµ‹è¯•åœºæ™¯ï¼ˆReplica - å¿…éœ€ï¼‰

**Replica æ˜¯å°å‹é«˜è´¨é‡åœºæ™¯ï¼Œç”¨äºæµ‹è¯•å’Œå¼€å‘**ï¼š

```bash
cd $HABITAT_DATA_DIR/scene_datasets

# ä¸‹è½½ Replica æ•°æ®é›†ï¼ˆ~2GBï¼‰
# æ–¹æ³•1ï¼šä½¿ç”¨å®˜æ–¹è„šæœ¬
python -m habitat_sim.utils.datasets_download \
    --username <ä½ çš„ç”¨æˆ·å> \
    --password <ä½ çš„å¯†ç > \
    --uids replica_cad_dataset

# æ–¹æ³•2ï¼šæ‰‹åŠ¨ä¸‹è½½
# è®¿é—®ï¼šhttps://github.com/facebookresearch/habitat-sim/blob/main/DATASETS.md
# ä¸‹è½½ replica_v1.zip
wget https://dl.fbaipublicfiles.com/habitat/replica_cad_dataset.zip

# è§£å‹
unzip replica_cad_dataset.zip -d replica/
rm replica_cad_dataset.zip

# éªŒè¯ï¼ˆåº”è¯¥åŒ…å« 18 ä¸ªåœºæ™¯ï¼‰
ls replica/
# é¢„æœŸè¾“å‡ºï¼šapartment_0, frl_apartment_0, hotel_0, office_0, room_0, ç­‰
```

### 3.3 ä¸‹è½½ HM3D æ•°æ®é›†ï¼ˆå¯é€‰ï¼Œè®­ç»ƒç”¨ï¼‰

**âš ï¸ HM3D éå¸¸å¤§ï¼ˆ~2.5TBï¼‰ï¼Œä»…åœ¨è®­ç»ƒæ—¶éœ€è¦**ï¼š

```bash
# HM3D éœ€è¦ç”³è¯·è®¿é—®æƒé™
# 1. è®¿é—®ï¼šhttps://aihabitat.org/datasets/hm3d/
# 2. å¡«å†™ç”³è¯·è¡¨æ ¼ï¼ˆå­¦æœ¯ç”¨é€”ï¼‰
# 3. è·å¾—ä¸‹è½½é“¾æ¥

# ä¸‹è½½ HM3D minivalï¼ˆè¾ƒå°ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•ï¼Œ~10GBï¼‰
cd $HABITAT_DATA_DIR/scene_datasets
mkdir -p hm3d

# ä½¿ç”¨æä¾›çš„ä¸‹è½½è„šæœ¬ï¼ˆéœ€è¦æ›¿æ¢ä½ çš„ tokenï¼‰
python -m habitat_sim.utils.datasets_download \
    --username <ä½ çš„ç”¨æˆ·å> \
    --password <ä½ çš„å¯†ç > \
    --uids hm3d_minival

# æˆ–è€…ä¸‹è½½å®Œæ•´è®­ç»ƒé›†ï¼ˆ~2.5TBï¼Œéœ€è¦å¤§é‡æ—¶é—´å’Œå­˜å‚¨ï¼‰
# python -m habitat_sim.utils.datasets_download \
#     --username <ç”¨æˆ·å> \
#     --password <å¯†ç > \
#     --uids hm3d_train_v0.2

# éªŒè¯
ls hm3d/
```

### 3.4 ä¸‹è½½ ObjectNav ä»»åŠ¡æ•°æ®

```bash
cd $HABITAT_DATA_DIR/datasets

# ä¸‹è½½ ObjectNav episodesï¼ˆHM3Dç‰ˆæœ¬ï¼‰
wget https://dl.fbaipublicfiles.com/habitat/data/datasets/objectnav/hm3d/v1/objectnav_hm3d_v1.zip

# è§£å‹
unzip objectnav_hm3d_v1.zip -d objectnav/hm3d/v1/
rm objectnav_hm3d_v1.zip

# éªŒè¯
ls objectnav/hm3d/v1/
# é¢„æœŸï¼štrain/, val/, val_mini/ ç­‰ç›®å½•
```

### 3.5 é…ç½®æ•°æ®é›†è·¯å¾„

åˆ›å»º Habitat é…ç½®æ–‡ä»¶ `~/.habitat/habitat.yaml`:

```bash
mkdir -p ~/.habitat
cat > ~/.habitat/habitat.yaml << 'EOF'
# Habitat æ•°æ®è·¯å¾„é…ç½®
data_path: ~/vla-gr-workspace/habitat-data

# åœºæ™¯æ•°æ®é›†è·¯å¾„
scene_datasets:
  hm3d: ~/vla-gr-workspace/habitat-data/scene_datasets/hm3d
  mp3d: ~/vla-gr-workspace/habitat-data/scene_datasets/mp3d
  replica: ~/vla-gr-workspace/habitat-data/scene_datasets/replica

# ä»»åŠ¡æ•°æ®é›†è·¯å¾„
datasets:
  objectnav:
    hm3d: ~/vla-gr-workspace/habitat-data/datasets/objectnav/hm3d/v1
  pointnav:
    gibson: ~/vla-gr-workspace/habitat-data/datasets/pointnav/gibson/v1
    mp3d: ~/vla-gr-workspace/habitat-data/datasets/pointnav/mp3d/v1
EOF
```

### 3.6 éªŒè¯æ•°æ®é›†å®Œæ•´æ€§

åˆ›å»ºéªŒè¯è„šæœ¬ `test_datasets.py`:

```python
import os
import habitat
from pathlib import Path

DATA_DIR = Path(os.environ['HABITAT_DATA_DIR'])

print("ğŸ” æ£€æŸ¥æ•°æ®é›†...")

# æ£€æŸ¥åœºæ™¯æ•°æ®é›†
replica_path = DATA_DIR / "scene_datasets" / "replica"
if replica_path.exists():
    scenes = list(replica_path.glob("*.glb"))
    print(f"âœ“ Replica: {len(scenes)} ä¸ªåœºæ™¯")
else:
    print("âœ— Replica æœªæ‰¾åˆ°")

hm3d_path = DATA_DIR / "scene_datasets" / "hm3d"
if hm3d_path.exists():
    scenes = list(hm3d_path.glob("*/*.glb"))
    print(f"âœ“ HM3D: {len(scenes)} ä¸ªåœºæ™¯")
else:
    print("âš  HM3D æœªæ‰¾åˆ°ï¼ˆå¯é€‰ï¼‰")

# æ£€æŸ¥ä»»åŠ¡æ•°æ®
objectnav_path = DATA_DIR / "datasets" / "objectnav" / "hm3d" / "v1"
if objectnav_path.exists():
    print(f"âœ“ ObjectNav æ•°æ®é›†å­˜åœ¨")
else:
    print("âœ— ObjectNav æ•°æ®é›†æœªæ‰¾åˆ°")

print("\nâœ… æ•°æ®é›†éªŒè¯å®Œæˆ")
```

è¿è¡Œï¼š

```bash
python test_datasets.py
```

---

## ğŸ¤— é˜¶æ®µå››ï¼šHugging Face æ¨¡å‹éƒ¨ç½²

### 4.1 é…ç½® Hugging Face è®¿é—®

```bash
# å®‰è£… Hugging Face CLI
pip install huggingface-hub

# ç™»å½•ï¼ˆå¯é€‰ï¼Œç”¨äºç§æœ‰æ¨¡å‹ï¼‰
huggingface-cli login
# è¾“å…¥ä½ çš„ tokenï¼ˆä» https://huggingface.co/settings/tokens è·å–ï¼‰

# è®¾ç½®ç¼“å­˜ç›®å½•
export HF_HOME=~/vla-gr-workspace/huggingface-cache
mkdir -p $HF_HOME
```

### 4.2 ä¸‹è½½ Microsoft Phi-2 æ¨¡å‹

**Phi-2 æ˜¯ä¸»è¦çš„è¯­è¨€æ¨¡å‹ï¼ˆ2.7B å‚æ•°ï¼‰**ï¼š

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ Python é¢„ä¸‹è½½
python << 'EOF'
from transformers import AutoModel, AutoTokenizer

print("ğŸ“¥ ä¸‹è½½ Phi-2 æ¨¡å‹...")
model_name = "microsoft/phi-2"

# ä¸‹è½½ tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    trust_remote_code=True,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print(f"âœ“ Tokenizer ä¸‹è½½å®Œæˆ")

# ä¸‹è½½æ¨¡å‹
model = AutoModel.from_pretrained(
    model_name,
    trust_remote_code=True,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print(f"âœ“ Phi-2 æ¨¡å‹ä¸‹è½½å®Œæˆ")
print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B")
EOF
```

**æ¨¡å‹æ–‡ä»¶ä½ç½®**ï¼š`~/vla-gr-workspace/huggingface-cache/models--microsoft--phi-2/`

**æ–‡ä»¶å¤§å°**ï¼šçº¦ 5.5GB

### 4.3 ä¸‹è½½ CLIP æ¨¡å‹

**CLIP ç”¨äºè§†è§‰-è¯­è¨€å¯¹é½**ï¼š

```bash
python << 'EOF'
from transformers import CLIPModel, CLIPProcessor

print("ğŸ“¥ ä¸‹è½½ CLIP æ¨¡å‹...")
model_name = "openai/clip-vit-base-patch32"

processor = CLIPProcessor.from_pretrained(
    model_name,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print("âœ“ CLIP Processor ä¸‹è½½å®Œæˆ")

model = CLIPModel.from_pretrained(
    model_name,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print("âœ“ CLIP æ¨¡å‹ä¸‹è½½å®Œæˆ")
EOF
```

**æ¨¡å‹æ–‡ä»¶ä½ç½®**ï¼š`~/vla-gr-workspace/huggingface-cache/models--openai--clip-vit-base-patch32/`

**æ–‡ä»¶å¤§å°**ï¼šçº¦ 600MB

### 4.4 ä¸‹è½½ BERT æ¨¡å‹ï¼ˆåå¤‡ï¼‰

```bash
python << 'EOF'
from transformers import BertModel, BertTokenizer

print("ğŸ“¥ ä¸‹è½½ BERT æ¨¡å‹...")
model_name = "bert-base-uncased"

tokenizer = BertTokenizer.from_pretrained(
    model_name,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
model = BertModel.from_pretrained(
    model_name,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print("âœ“ BERT æ¨¡å‹ä¸‹è½½å®Œæˆ")
EOF
```

### 4.5 é…ç½®æ¨¡å‹ç¼“å­˜è·¯å¾„

åœ¨é¡¹ç›®çš„ `config.yaml` ä¸­ï¼ˆç¨åä¼šåˆ›å»ºï¼‰ï¼Œç¡®ä¿è®¾ç½®ï¼š

```yaml
model:
  language:
    model: "microsoft/phi-2"
    cache_dir: "~/vla-gr-workspace/huggingface-cache"
    local_files_only: false  # é¦–æ¬¡ä¸‹è½½è®¾ä¸º falseï¼Œä¹‹åå¯ä»¥è®¾ä¸º true
```

### 4.6 éªŒè¯æ¨¡å‹åŠ è½½

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_models.py`:

```python
import torch
from transformers import AutoModel, AutoTokenizer, CLIPModel, BertModel

print("ğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½...")

# æµ‹è¯• Phi-2
print("\n1. Phi-2...")
phi_tokenizer = AutoTokenizer.from_pretrained(
    "microsoft/phi-2",
    trust_remote_code=True,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
phi_model = AutoModel.from_pretrained(
    "microsoft/phi-2",
    trust_remote_code=True,
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print(f"   âœ“ Phi-2 åŠ è½½æˆåŠŸ ({sum(p.numel() for p in phi_model.parameters()) / 1e9:.2f}B å‚æ•°)")

# æµ‹è¯• CLIP
print("\n2. CLIP...")
clip_model = CLIPModel.from_pretrained(
    "openai/clip-vit-base-patch32",
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print(f"   âœ“ CLIP åŠ è½½æˆåŠŸ")

# æµ‹è¯• BERT
print("\n3. BERT...")
bert_model = BertModel.from_pretrained(
    "bert-base-uncased",
    cache_dir="~/vla-gr-workspace/huggingface-cache"
)
print(f"   âœ“ BERT åŠ è½½æˆåŠŸ")

# GPU æµ‹è¯•
if torch.cuda.is_available():
    print("\n4. GPU æµ‹è¯•...")
    device = torch.device("cuda")
    bert_model.to(device)
    print(f"   âœ“ æ¨¡å‹æˆåŠŸåŠ è½½åˆ° GPU")
    print(f"   GPU å†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

print("\nâœ… æ‰€æœ‰æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
```

è¿è¡Œï¼š

```bash
python test_models.py
```

---

## ğŸš€ é˜¶æ®µäº”ï¼šé¡¹ç›®å®‰è£…å’Œé…ç½®

### 5.1 å…‹éš†é¡¹ç›®ä»£ç 

```bash
cd ~/vla-gr-workspace

# å…‹éš†ä½ çš„ VLA-GR ä»“åº“
git clone https://github.com/Amagerd1113/VLA-GR.git
cd VLA-GR

# æ£€æŸ¥åˆ†æ”¯
git branch -a
git checkout claude/habitat-deployment-guide-011CUwwV7U9zmVCFZwVjTzCu
```

### 5.2 å®‰è£…é¡¹ç›®ï¼ˆeditable modeï¼‰

```bash
# ç¡®ä¿åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
source ~/vla-gr-workspace/vla-gr-env/bin/activate

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# ä»¥å¯ç¼–è¾‘æ¨¡å¼å®‰è£…é¡¹ç›®
pip install -e .

# éªŒè¯å®‰è£…
vla-gr-train --help
vla-gr-evaluate --help
```

### 5.3 é…ç½® config.yaml

é¡¹ç›®å·²åŒ…å«å¤šä¸ªé…ç½®æ–‡ä»¶ï¼š
- `config.yaml`: åŸºç¡€é…ç½®
- `config_rtx4060.yaml`: RTX 4060 ä¼˜åŒ–é…ç½®ï¼ˆ8GB æ˜¾å­˜ï¼‰
- `config_server.yaml`: æœåŠ¡å™¨é…ç½®ï¼ˆå¤šGPUï¼‰

æ ¹æ®ä½ çš„ç¡¬ä»¶é€‰æ‹©åˆé€‚çš„é…ç½®ï¼š

**å¯¹äº RTX 4060 (8GB æ˜¾å­˜)**ï¼š

```bash
# å¤åˆ¶å¹¶ç¼–è¾‘é…ç½®
cp config_rtx4060.yaml config_active.yaml
nano config_active.yaml
```

**ä¿®æ”¹å…³é”®è·¯å¾„**ï¼š

```yaml
# æ•°æ®è·¯å¾„
data:
  habitat_data_dir: ~/vla-gr-workspace/habitat-data
  scene_dataset: "replica"  # æˆ– "hm3d" ï¼ˆå¦‚æœä¸‹è½½äº†ï¼‰
  episodes_dir: ~/vla-gr-workspace/habitat-data/datasets/objectnav/hm3d/v1

# æ¨¡å‹ç¼“å­˜
model:
  language:
    model: "microsoft/phi-2"
    cache_dir: ~/vla-gr-workspace/huggingface-cache

# è¾“å‡ºç›®å½•
training:
  output_dir: ~/vla-gr-workspace/outputs
  checkpoint_dir: ~/vla-gr-workspace/checkpoints
  log_dir: ~/vla-gr-workspace/logs
```

**å¯¹äºæœåŠ¡å™¨ï¼ˆå¤šGPUï¼‰**ï¼š

```bash
cp config_server.yaml config_active.yaml
# åŒæ ·ä¿®æ”¹è·¯å¾„
```

### 5.4 è®¾ç½® Weights & Biasesï¼ˆå¯é€‰ï¼‰

å¦‚æœè¦ä½¿ç”¨ W&B è¿›è¡Œè®­ç»ƒç›‘æ§ï¼š

```bash
# å®‰è£…ï¼ˆå·²åœ¨ requirements.txt ä¸­ï¼‰
pip install wandb

# ç™»å½•
wandb login
# è¾“å…¥ä½ çš„ API keyï¼ˆä» https://wandb.ai/authorize è·å–ï¼‰

# åœ¨ config_active.yaml ä¸­å¯ç”¨
# wandb:
#   enabled: true
#   project: "vla-gr-navigation"
#   entity: "your-username"
```

### 5.5 åˆ›å»ºè¾“å‡ºç›®å½•

```bash
# åˆ›å»ºæ‰€æœ‰å¿…éœ€çš„è¾“å‡ºç›®å½•
mkdir -p ~/vla-gr-workspace/outputs
mkdir -p ~/vla-gr-workspace/checkpoints
mkdir -p ~/vla-gr-workspace/logs
mkdir -p ~/vla-gr-workspace/visualizations
mkdir -p ~/vla-gr-workspace/exports

# é“¾æ¥åˆ°é¡¹ç›®ç›®å½•ï¼ˆå¯é€‰ï¼‰
ln -s ~/vla-gr-workspace/outputs ~/vla-gr-workspace/VLA-GR/outputs
ln -s ~/vla-gr-workspace/checkpoints ~/vla-gr-workspace/VLA-GR/checkpoints
ln -s ~/vla-gr-workspace/logs ~/vla-gr-workspace/VLA-GR/logs
```

---

## âœ… é˜¶æ®µå…­ï¼šéªŒè¯å’Œæµ‹è¯•

### 6.1 è¿è¡Œå¯¼å…¥æµ‹è¯•

åˆ›å»º `test_imports.py`:

```python
"""æµ‹è¯•æ‰€æœ‰å…³é”®å¯¼å…¥"""
import sys

def test_imports():
    tests = []

    # åŸºç¡€åº“
    try:
        import torch
        tests.append(("PyTorch", torch.__version__, True))
    except Exception as e:
        tests.append(("PyTorch", str(e), False))

    # Habitat
    try:
        import habitat
        import habitat_sim
        tests.append(("Habitat-Sim", habitat_sim.__version__, True))
        tests.append(("Habitat-Lab", habitat.__version__, True))
    except Exception as e:
        tests.append(("Habitat", str(e), False))

    # Transformers
    try:
        import transformers
        tests.append(("Transformers", transformers.__version__, True))
    except Exception as e:
        tests.append(("Transformers", str(e), False))

    # é¡¹ç›®æ¨¡å—
    try:
        from src.core.vla_gr_agent import ConferenceVLAGRAgent
        tests.append(("VLA-GR Agent", "OK", True))
    except Exception as e:
        tests.append(("VLA-GR Agent", str(e), False))

    try:
        from src.environments.habitat_env_v3 import HabitatNavigationEnv
        tests.append(("Habitat Env V3", "OK", True))
    except Exception as e:
        tests.append(("Habitat Env V3", str(e), False))

    try:
        from src.training.train import TrainingPipeline
        tests.append(("Training Pipeline", "OK", True))
    except Exception as e:
        tests.append(("Training Pipeline", str(e), False))

    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("å¯¼å…¥æµ‹è¯•ç»“æœ")
    print("="*60)

    all_passed = True
    for name, version, passed in tests:
        status = "âœ“" if passed else "âœ—"
        print(f"{status} {name:20s} {version}")
        if not passed:
            all_passed = False

    print("="*60)

    if all_passed:
        print("âœ… æ‰€æœ‰å¯¼å…¥æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âŒ éƒ¨åˆ†å¯¼å…¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return 1

if __name__ == "__main__":
    sys.exit(test_imports())
```

è¿è¡Œï¼š

```bash
cd ~/vla-gr-workspace/VLA-GR
python test_imports.py
```

### 6.2 è¿è¡Œ Habitat ç¯å¢ƒæµ‹è¯•

åˆ›å»º `test_habitat_env.py`:

```python
"""æµ‹è¯• Habitat ç¯å¢ƒ"""
import os
os.environ['HABITAT_DATA_DIR'] = os.path.expanduser('~/vla-gr-workspace/habitat-data')

from src.environments.habitat_env_v3 import HabitatNavigationEnv
import numpy as np

print("ğŸ§ª æµ‹è¯• Habitat ç¯å¢ƒ...")

# åˆ›å»ºç¯å¢ƒ
env = HabitatNavigationEnv(
    scene_id="replica/apartment_0.glb",
    task_type="objectnav",
    max_episode_steps=100
)

print(f"âœ“ ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
print(f"  è§‚å¯Ÿç©ºé—´: {env.observation_space}")
print(f"  åŠ¨ä½œç©ºé—´: {env.action_space}")

# é‡ç½®ç¯å¢ƒ
obs, info = env.reset()
print(f"âœ“ ç¯å¢ƒé‡ç½®æˆåŠŸ")
print(f"  RGB shape: {obs['rgb'].shape}")
print(f"  Depth shape: {obs['depth'].shape}")
print(f"  ä»»åŠ¡æŒ‡ä»¤: {obs.get('instruction', 'N/A')}")

# è¿è¡Œå‡ æ­¥
for i in range(5):
    action = env.action_space.sample()
    obs, reward, done, truncated, info = env.step(action)
    print(f"  Step {i+1}: reward={reward:.3f}, done={done}")
    if done:
        break

env.close()
print("âœ… Habitat ç¯å¢ƒæµ‹è¯•é€šè¿‡ï¼")
```

è¿è¡Œï¼š

```bash
python test_habitat_env.py
```

### 6.3 è¿è¡Œæ¨¡å‹åŠ è½½æµ‹è¯•

åˆ›å»º `test_agent.py`:

```python
"""æµ‹è¯• VLA-GR Agent"""
import os
os.environ['HABITAT_DATA_DIR'] = os.path.expanduser('~/vla-gr-workspace/habitat-data')
os.environ['HF_HOME'] = os.path.expanduser('~/vla-gr-workspace/huggingface-cache')

import torch
from src.core.vla_gr_agent import ConferenceVLAGRAgent
from omegaconf import OmegaConf

print("ğŸ§ª æµ‹è¯• VLA-GR Agent...")

# åŠ è½½é…ç½®
config = OmegaConf.load("config_active.yaml")

# åˆ›å»º Agent
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
agent = ConferenceVLAGRAgent(config, device=device)

print(f"âœ“ Agent åˆ›å»ºæˆåŠŸ")
print(f"  è®¾å¤‡: {device}")
print(f"  è¯­è¨€æ¨¡å‹: {config.model.language.model}")

# æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨éšæœºæ•°æ®ï¼‰
batch_size = 2
rgb = torch.randn(batch_size, 3, 224, 224).to(device)
depth = torch.randn(batch_size, 1, 224, 224).to(device)
instruction = ["go to the chair"] * batch_size

print(f"âœ“ å‡†å¤‡æµ‹è¯•è¾“å…¥")

with torch.no_grad():
    output = agent.forward(rgb, depth, instruction)

print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
print(f"  è¾“å‡º keys: {output.keys()}")
print(f"  Action shape: {output['action'].shape}")

# æ£€æŸ¥ GPU å†…å­˜
if torch.cuda.is_available():
    print(f"  GPU å†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

print("âœ… Agent æµ‹è¯•é€šè¿‡ï¼")
```

è¿è¡Œï¼š

```bash
python test_agent.py
```

### 6.4 è¿è¡Œç®€å•æ¨ç†æµ‹è¯•

åˆ›å»º `test_inference.py`:

```python
"""ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•"""
import os
os.environ['HABITAT_DATA_DIR'] = os.path.expanduser('~/vla-gr-workspace/habitat-data')
os.environ['HF_HOME'] = os.path.expanduser('~/vla-gr-workspace/huggingface-cache')

import torch
from src.core.vla_gr_agent import ConferenceVLAGRAgent
from src.environments.habitat_env_v3 import HabitatNavigationEnv
from omegaconf import OmegaConf

print("ğŸ§ª ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•...")

# åŠ è½½é…ç½®
config = OmegaConf.load("config_active.yaml")

# åˆ›å»ºç¯å¢ƒå’Œ Agent
env = HabitatNavigationEnv(
    scene_id="replica/apartment_0.glb",
    task_type="objectnav",
    max_episode_steps=50
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
agent = ConferenceVLAGRAgent(config, device=device)
agent.eval()

print(f"âœ“ ç¯å¢ƒå’Œ Agent å°±ç»ª")

# è¿è¡Œä¸€ä¸ª episode
obs, info = env.reset()
episode_reward = 0
steps = 0

print(f"  ä»»åŠ¡: {obs.get('instruction', 'navigate')}")

for step in range(10):  # è¿è¡Œ 10 æ­¥
    # å‡†å¤‡è¾“å…¥
    rgb = torch.from_numpy(obs['rgb']).permute(2, 0, 1).unsqueeze(0).float().to(device) / 255.0
    depth = torch.from_numpy(obs['depth']).unsqueeze(0).unsqueeze(0).float().to(device)
    instruction = [obs.get('instruction', 'go forward')]

    # Agent æ¨ç†
    with torch.no_grad():
        output = agent.forward(rgb, depth, instruction)

    # è·å–åŠ¨ä½œ
    action_probs = torch.softmax(output['action'], dim=-1)
    action = torch.argmax(action_probs, dim=-1).item()

    # æ‰§è¡ŒåŠ¨ä½œ
    obs, reward, done, truncated, info = env.step(action)
    episode_reward += reward
    steps += 1

    print(f"  Step {steps}: action={action}, reward={reward:.3f}, done={done}")

    if done or truncated:
        break

env.close()

print(f"âœ“ Episode å®Œæˆ")
print(f"  æ€»æ­¥æ•°: {steps}")
print(f"  æ€»å¥–åŠ±: {episode_reward:.3f}")
print("âœ… ç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•é€šè¿‡ï¼")
```

è¿è¡Œï¼š

```bash
python test_inference.py
```

### 6.5 æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨

åˆ›å»º `test_gpu_memory.py`:

```python
"""GPU å†…å­˜ä½¿ç”¨æµ‹è¯•"""
import torch
import os
os.environ['HABITAT_DATA_DIR'] = os.path.expanduser('~/vla-gr-workspace/habitat-data')
os.environ['HF_HOME'] = os.path.expanduser('~/vla-gr-workspace/huggingface-cache')

from src.core.vla_gr_agent import ConferenceVLAGRAgent
from omegaconf import OmegaConf

if not torch.cuda.is_available():
    print("âŒ CUDA ä¸å¯ç”¨")
    exit(1)

print("ğŸ” GPU å†…å­˜åˆ†æ...")

device = torch.device("cuda")
torch.cuda.reset_peak_memory_stats()

# åŠ è½½é…ç½®
config = OmegaConf.load("config_active.yaml")

print(f"åˆå§‹ GPU å†…å­˜: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

# åˆ›å»º Agent
agent = ConferenceVLAGRAgent(config, device=device)
print(f"Agent åŠ è½½å: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

# æ¨¡æ‹Ÿè®­ç»ƒæ‰¹æ¬¡
batch_size = config.training.batch_size
rgb = torch.randn(batch_size, 3, 224, 224).to(device)
depth = torch.randn(batch_size, 1, 224, 224).to(device)
instruction = ["test"] * batch_size

# å‰å‘ä¼ æ’­
output = agent.forward(rgb, depth, instruction)
print(f"å‰å‘ä¼ æ’­å: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

# æ¨¡æ‹Ÿåå‘ä¼ æ’­
loss = output['action'].sum()
loss.backward()
print(f"åå‘ä¼ æ’­å: {torch.cuda.memory_allocated() / 1e9:.2f} GB")

# å³°å€¼å†…å­˜
peak_memory = torch.cuda.max_memory_allocated() / 1e9
print(f"\nå³°å€¼ GPU å†…å­˜: {peak_memory:.2f} GB")

# æ£€æŸ¥æ˜¯å¦è¶…å‡ºæ˜¾å­˜
gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
print(f"GPU æ€»å†…å­˜: {gpu_memory:.2f} GB")

if peak_memory < gpu_memory * 0.9:
    print("âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸")
else:
    print("âš ï¸  å†…å­˜ä½¿ç”¨æ¥è¿‘ä¸Šé™ï¼Œè€ƒè™‘å‡å° batch size æˆ–å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹")
```

è¿è¡Œï¼š

```bash
python test_gpu_memory.py
```

---

## ğŸ‹ï¸ é˜¶æ®µä¸ƒï¼šè®­ç»ƒå’Œè¯„ä¼°

### 7.1 å‡†å¤‡è®­ç»ƒé…ç½®

ç¡®ä¿ä½ çš„ `config_active.yaml` é…ç½®æ­£ç¡®ï¼š

**RTX 4060 (8GB) é…ç½®**ï¼š

```yaml
training:
  batch_size: 4              # å°æ‰¹æ¬¡
  gradient_accumulation: 8   # ç´¯ç§¯æ¢¯åº¦æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡
  mixed_precision: true      # FP16
  gradient_checkpointing: true  # å‡å°‘å†…å­˜
  max_steps: 100000
  learning_rate: 3e-5

model:
  use_lora: true             # LoRA å¾®è°ƒ
  lora_rank: 16
  lora_alpha: 32
```

**æœåŠ¡å™¨é…ç½®**ï¼š

```yaml
training:
  batch_size: 32
  gradient_accumulation: 1
  mixed_precision: "bf16"    # BF16ï¼ˆA100/H100ï¼‰
  distributed: true
  num_gpus: 4
  max_steps: 100000
  learning_rate: 5e-5
```

### 7.2 è¿è¡Œå°è§„æ¨¡è®­ç»ƒæµ‹è¯•

é¦–å…ˆè¿è¡Œä¸€ä¸ªçŸ­æ—¶é—´çš„è®­ç»ƒæµ‹è¯•ï¼Œç¡®ä¿ä¸€åˆ‡æ­£å¸¸ï¼š

```bash
# ä¿®æ”¹é…ç½®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
cp config_active.yaml config_test.yaml

# ç¼–è¾‘ config_test.yamlï¼Œè®¾ç½®ï¼š
# training.max_steps: 100
# training.eval_every: 50
# training.save_every: 50

# è¿è¡Œæµ‹è¯•è®­ç»ƒ
vla-gr-train \
    --config config_test.yaml \
    --output-dir ~/vla-gr-workspace/outputs/test_run \
    --num-episodes 10

# æˆ–è€…ç›´æ¥ä½¿ç”¨ Python
python -m src.training.train \
    --config config_test.yaml \
    --output-dir ~/vla-gr-workspace/outputs/test_run
```

**é¢„æœŸè¾“å‡º**ï¼š

```
ğŸš€ VLA-GR Training Pipeline
ğŸ“‹ Configuration:
   - Device: cuda
   - Batch size: 4
   - Learning rate: 3e-05
   - Mixed precision: True

ğŸ“Š Loading datasets...
âœ“ Train dataset: 10 episodes
âœ“ Val dataset: 2 episodes

ğŸ—ï¸ Initializing model...
âœ“ VLA-GR Agent created
   Parameters: 2.8B total, 45M trainable (LoRA)

ğŸ¯ Starting training...

Step 1/100 | Loss: 2.456 | LR: 3.00e-05 | Time: 2.3s
Step 10/100 | Loss: 1.823 | LR: 3.00e-05 | Time: 1.8s
...
Step 50/100 | Loss: 0.945 | LR: 3.00e-05 | Time: 1.7s
ğŸ“Š Validation | Val Loss: 1.123 | Success Rate: 15.0%
...
Step 100/100 | Loss: 0.712 | LR: 3.00e-05 | Time: 1.6s

âœ… Training test completed successfully!
```

### 7.3 å¯åŠ¨å®Œæ•´è®­ç»ƒ

**å• GPU è®­ç»ƒ**ï¼š

```bash
# ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·
vla-gr-train \
    --config config_active.yaml \
    --output-dir ~/vla-gr-workspace/outputs/full_training \
    --resume-from-checkpoint ~/vla-gr-workspace/checkpoints/latest.pt

# æˆ–ä½¿ç”¨ Python
python -m src.training.train \
    --config config_active.yaml \
    --output-dir ~/vla-gr-workspace/outputs/full_training

# ä½¿ç”¨ nohup åå°è¿è¡Œ
nohup vla-gr-train \
    --config config_active.yaml \
    --output-dir ~/vla-gr-workspace/outputs/full_training \
    > ~/vla-gr-workspace/logs/training.log 2>&1 &

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f ~/vla-gr-workspace/logs/training.log
```

**å¤š GPU åˆ†å¸ƒå¼è®­ç»ƒ**ï¼š

```bash
# ä½¿ç”¨ torchrunï¼ˆæ¨èï¼‰
torchrun \
    --nproc_per_node=4 \
    --master_port=29500 \
    -m src.training.train \
    --config config_server.yaml \
    --output-dir ~/vla-gr-workspace/outputs/distributed_training

# æˆ–ä½¿ç”¨ accelerate
accelerate launch \
    --multi_gpu \
    --num_processes=4 \
    -m src.training.train \
    --config config_server.yaml \
    --output-dir ~/vla-gr-workspace/outputs/distributed_training
```

### 7.4 ç›‘æ§è®­ç»ƒè¿›åº¦

**ä½¿ç”¨ TensorBoard**ï¼š

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir ~/vla-gr-workspace/logs --port 6006

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼šhttp://localhost:6006
```

**ä½¿ç”¨ Weights & Biases**ï¼š

```bash
# å¦‚æœå¯ç”¨äº† W&Bï¼Œè®¿é—®ï¼š
# https://wandb.ai/<your-username>/vla-gr-navigation
```

**ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·**ï¼š

```bash
# æŸ¥çœ‹æœ€æ–°æ£€æŸ¥ç‚¹
ls -lht ~/vla-gr-workspace/checkpoints/

# æ£€æŸ¥ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# ç›‘æ§æ—¥å¿—
tail -f ~/vla-gr-workspace/logs/training.log | grep -E "(Step|Loss|Success)"
```

### 7.5 è¿è¡Œè¯„ä¼°

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æˆ–ä¹‹åè¿è¡Œè¯„ä¼°ï¼š

```bash
# è¯„ä¼°æœ€æ–°æ£€æŸ¥ç‚¹
vla-gr-evaluate \
    --config config_active.yaml \
    --checkpoint ~/vla-gr-workspace/checkpoints/latest.pt \
    --output-dir ~/vla-gr-workspace/outputs/evaluation \
    --num-episodes 100

# æˆ–ä½¿ç”¨ Python
python -m src.evaluation.evaluator \
    --config config_active.yaml \
    --checkpoint ~/vla-gr-workspace/checkpoints/latest.pt \
    --num-episodes 100 \
    --save-trajectories

# ä¼šè®®çº§è¯„ä¼°ï¼ˆè¯¦ç»†æŒ‡æ ‡ï¼‰
python scripts/run_evaluation.py \
    --config config_active.yaml \
    --checkpoint ~/vla-gr-workspace/checkpoints/best.pt \
    --output-dir ~/vla-gr-workspace/outputs/conference_eval \
    --split val \
    --num-episodes 500
```

**é¢„æœŸè¯„ä¼°è¾“å‡º**ï¼š

```
ğŸ¯ VLA-GR Evaluation
ğŸ“Š Loading checkpoint: checkpoints/latest.pt

ğŸƒ Running evaluation on 100 episodes...

Episode 1/100 | Success: True | SPL: 0.85 | Steps: 45
Episode 10/100 | Success: False | SPL: 0.00 | Steps: 500
...
Episode 100/100 | Success: True | SPL: 0.72 | Steps: 67

ğŸ“ˆ Evaluation Results:
   - Success Rate: 77.4%
   - SPL: 0.645
   - Collision Rate: 16.5%
   - Avg Steps: 124.5
   - Avg Distance to Goal: 0.38m

âœ… Evaluation complete!
Results saved to: outputs/evaluation/results.json
```

---

## ğŸ”§ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: Habitat-Sim ç¼–è¯‘å¤±è´¥

**é—®é¢˜**ï¼šç¼–è¯‘ Habitat-Sim æ—¶å‡ºé”™

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# ç¡®ä¿å®‰è£…äº†æ‰€æœ‰ç¼–è¯‘ä¾èµ–
sudo apt-get install -y build-essential cmake git ninja-build

# æ£€æŸ¥ GCC ç‰ˆæœ¬ï¼ˆéœ€è¦ 7.x æˆ–æ›´é«˜ï¼‰
gcc --version

# æ¸…ç†å¹¶é‡æ–°ç¼–è¯‘
cd ~/vla-gr-workspace/habitat-build/habitat-sim
rm -rf build
python setup.py clean
python setup.py install --headless --with-cuda
```

### Q2: CUDA out of memory

**é—®é¢˜**ï¼šè®­ç»ƒæ—¶ GPU å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š

```yaml
# åœ¨ config_active.yaml ä¸­è°ƒæ•´ï¼š
training:
  batch_size: 2              # å‡å°æ‰¹æ¬¡
  gradient_accumulation: 16  # å¢åŠ ç´¯ç§¯æ­¥æ•°
  gradient_checkpointing: true  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

model:
  use_lora: true             # ä½¿ç”¨ LoRA
  freeze_vision_encoder: true  # å†»ç»“è§†è§‰ç¼–ç å™¨
```

### Q3: Hugging Face æ¨¡å‹ä¸‹è½½å¤±è´¥

**é—®é¢˜**ï¼šç½‘ç»œé—®é¢˜å¯¼è‡´ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# ä½¿ç”¨é•œåƒç«™
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–æ‰‹åŠ¨ä¸‹è½½åè®¾ç½®æœ¬åœ°è·¯å¾„
# åœ¨ config.yaml ä¸­ï¼š
model:
  language:
    model: "/path/to/local/phi-2"
    local_files_only: true
```

### Q4: Habitat åœºæ™¯æœªæ‰¾åˆ°

**é—®é¢˜**ï¼š`Scene dataset not found`

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $HABITAT_DATA_DIR

# éªŒè¯åœºæ™¯æ–‡ä»¶
ls $HABITAT_DATA_DIR/scene_datasets/replica/

# åœ¨ Python ä¸­æ˜ç¡®è®¾ç½®è·¯å¾„
import os
os.environ['HABITAT_DATA_DIR'] = '/your/path/to/habitat-data'
```

### Q5: è®­ç»ƒé€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®**ï¼š

```yaml
# å¯ç”¨æ•°æ®åŠ è½½ä¼˜åŒ–
data:
  num_workers: 4              # å¤šè¿›ç¨‹æ•°æ®åŠ è½½
  prefetch_factor: 2          # é¢„å–æ‰¹æ¬¡
  pin_memory: true            # å›ºå®šå†…å­˜ï¼ˆGPU ä¼ è¾“æ›´å¿«ï¼‰

# å¯ç”¨ç¼–è¯‘ä¼˜åŒ–ï¼ˆPyTorch 2.0+ï¼‰
training:
  compile: true               # torch.compile
  compile_mode: "reduce-overhead"
```

### Q6: å¤š GPU è®­ç»ƒé—®é¢˜

**é—®é¢˜**ï¼šåˆ†å¸ƒå¼è®­ç»ƒå¡ä½æˆ–å‡ºé”™

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ£€æŸ¥ NCCLï¼ˆå¤š GPU é€šä¿¡ï¼‰
python -c "import torch; print(torch.cuda.nccl.version())"

# è®¾ç½®ç¯å¢ƒå˜é‡
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1  # å¦‚æœé‡åˆ° InfiniBand é—®é¢˜

# ä½¿ç”¨æ­£ç¡®çš„å¯åŠ¨æ–¹å¼
torchrun --nproc_per_node=4 ...
```

---

## ğŸ“š ç›®å½•ç»“æ„æ€»ç»“

**æœ€ç»ˆçš„å·¥ä½œç©ºé—´ç»“æ„**ï¼š

```
~/vla-gr-workspace/
â”œâ”€â”€ vla-gr-env/                    # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ VLA-GR/                        # é¡¹ç›®ä»£ç 
â”‚   â”œâ”€â”€ src/                       # æºä»£ç 
â”‚   â”œâ”€â”€ scripts/                   # è„šæœ¬
â”‚   â”œâ”€â”€ config_active.yaml         # æ´»åŠ¨é…ç½®
â”‚   â””â”€â”€ ...
â”œâ”€â”€ habitat-data/                  # Habitat æ•°æ®ï¼ˆ100GB - 3.5TBï¼‰
â”‚   â”œâ”€â”€ scene_datasets/
â”‚   â”‚   â”œâ”€â”€ replica/              # ~2GBï¼ˆå¿…éœ€ï¼‰
â”‚   â”‚   â””â”€â”€ hm3d/                 # ~2.5TBï¼ˆå¯é€‰ï¼‰
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ objectnav/
â”œâ”€â”€ huggingface-cache/             # HF æ¨¡å‹ç¼“å­˜ï¼ˆ~10GBï¼‰
â”‚   â”œâ”€â”€ models--microsoft--phi-2/
â”‚   â”œâ”€â”€ models--openai--clip-vit-base-patch32/
â”‚   â””â”€â”€ models--bert-base-uncased/
â”œâ”€â”€ outputs/                       # è®­ç»ƒè¾“å‡º
â”œâ”€â”€ checkpoints/                   # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                          # æ—¥å¿—æ–‡ä»¶
â””â”€â”€ habitat-build/                 # Habitat æ„å»ºç›®å½•ï¼ˆå¯åˆ é™¤ï¼‰
```

**å­˜å‚¨éœ€æ±‚æ€»ç»“**ï¼š

```
åŸºç¡€ç¯å¢ƒï¼ˆæµ‹è¯•/å¼€å‘ï¼‰:
  - è™šæ‹Ÿç¯å¢ƒ: ~5GB
  - Habitat-Sim/Lab: ~2GB
  - PyTorch + ä¾èµ–: ~8GB
  - Replica åœºæ™¯: ~2GB
  - HF æ¨¡å‹: ~10GB
  - æ€»è®¡: ~30GB

å®Œæ•´è®­ç»ƒç¯å¢ƒ:
  - åŸºç¡€ç¯å¢ƒ: ~30GB
  - HM3D æ•°æ®é›†: ~2.5TB
  - è®­ç»ƒè¾“å‡º/æ£€æŸ¥ç‚¹: ~50GB
  - æ€»è®¡: ~2.6TB
```

---

## ğŸ‰ å®Œæˆéƒ¨ç½²ï¼

æ­å–œï¼ä½ å·²ç»å®Œæˆäº† VLA-GR Habitat 0.3.3 çš„å®Œæ•´éƒ¨ç½²ã€‚

**ä¸‹ä¸€æ­¥**ï¼š

1. âœ… è¿è¡Œæ‰€æœ‰éªŒè¯æµ‹è¯•ï¼ˆé˜¶æ®µå…­ï¼‰
2. ğŸ§ª è¿è¡Œå°è§„æ¨¡è®­ç»ƒæµ‹è¯•
3. ğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒ
4. ğŸ“Š ç›‘æ§å’Œè¯„ä¼°ç»“æœ
5. ğŸ”§ æ ¹æ®æ€§èƒ½è°ƒä¼˜é…ç½®

**æœ‰ç”¨çš„å‘½ä»¤**ï¼š

```bash
# å¿«é€Ÿå¯åŠ¨è®­ç»ƒï¼ˆRTX 4060ï¼‰
vla-gr-train --config config_rtx4060.yaml

# å¿«é€Ÿå¯åŠ¨è®­ç»ƒï¼ˆæœåŠ¡å™¨ï¼‰
torchrun --nproc_per_node=4 -m src.training.train --config config_server.yaml

# è¯„ä¼°
vla-gr-evaluate --checkpoint checkpoints/best.pt --num-episodes 100

# ç›‘æ§
tensorboard --logdir logs

# GPU ç›‘æ§
watch -n 1 nvidia-smi
```

**è·å–å¸®åŠ©**ï¼š

- ğŸ“– æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£ï¼š`README.md`, `DEPLOYMENT_GUIDE.md`
- ğŸ› é‡åˆ°é—®é¢˜ï¼šæ£€æŸ¥ `BUG_FIXES_SUMMARY.md`
- ğŸ“š API å‚è€ƒï¼š`HABITAT_TRANSFORMERS_QUICK_REFERENCE.md`
- ğŸ”¬ ç†è®ºèƒŒæ™¯ï¼š`THEORETICAL_CONTRIBUTIONS.md`

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
